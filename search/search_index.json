{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"PRISME Documentation","text":""},{"location":"#power-reproducibility-and-inference-for-statistical-method-evaluation","title":"Power Reproducibility and Inference for Statistical Method Evaluation","text":"<p>PRISME is a MATLAB toolbox for empirical power estimation in neuroimaging. The goal of PRISME is to provide a generic power calculator tool applicable to most situations, addressing some of the limitations in power calculation within the field. </p>"},{"location":"#what-prisme-does","title":"What PRISME Does","text":"<p>PRISME calculates statistical power through repeated subsampling. The algorithm:</p> <ol> <li>Samples n subjects from your full dataset (N subjects)</li> <li>Fits a GLM to generate t-statistics for each brain variable</li> <li>Applies statistical inference methods to produce p-values and detect an effect if the obtained p-value is below a significance threshold</li> <li>Repeats this process R times (typically 500 repetitions - user defined)</li> <li>Compares detected effects against an estimated ground truth from the full dataset</li> <li>Returns power estimates for each variable and method</li> </ol> <p>Power is defined as the proportion of repetitions where an inference method correctly detects these effects.</p>"},{"location":"#key-features","title":"Key Features","text":"<p>Method-agnostic: Compare any statistical inference method that produces p-values from t-statistics. Currently implements 7 methods: Parametric (FDR/FWER), cNBS (FDR/FWER), Cluster Size, TFCE, and mv-cNBS. Please check the user guide for exact method names. More methods can be added by developers by following our specified API, please check the developer guide.</p> <p>Data-agnostic: Designed to work with multiple data types. For example, functional connectivity and voxel activation data</p> <p>Computational efficiency: Permutations are recycled to speed up power calculation comparisons over multiple methods. </p> <p>Test type support: Handles one-sample t-tests, two-sample t-tests, and correlation analyses with behavioral/clinical measures. Test types are automatically inferred from the input data.</p>"},{"location":"#installation","title":"Installation","text":"<p>Simply clone the repository and open the scripts in MATLAB.</p> <pre><code># Requirements: MATLAB (recommended version R2024a or later)\ngit clone https://github.com/neuroprismlab/PRISME-Brain-Power-Calculator.git\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Configure parameters in <code>setparams.m</code>, then run the three-step workflow:</p> <pre><code>% 1. Edit setparams.m with minimal required parameters:\n\n% Dataset path (required)\nParams.data_dir = './data/your_dataset.mat';\n\n% Output naming (optional - defaults to dataset name - this will name the directory storing the results)\nParams.output = 'my_power_analysis';\n\n% Sample sizes to test (required)\nParams.list_of_nsubset = {40, 80, 120, 200};\n\n% Number of repetitions \nParams.n_repetitions = 100;\n\n% Statistical inference methods to compare (required - which methods to use for this analysis)\nParams.all_cluster_stat_types = {'Parametric', 'Fast_TFCE_cpp', 'Constrained_cpp'};\n\n% 2. Run the workflow\nParams = setparams();  % Load all parameters\nrepetition_calculator(Params);  % Generate power samples\ncalculate_gt(Params);           % Compute ground truth\ncalculate_power_per_method(Params);  % Calculate power estimates\n</code></pre> <p>Results are saved to <code>./power_calculator_results/</code> by default under a directory named Params.output.</p> <p>See Configuration Parameters for all available <code>setparams.m</code> options and Running Workflows for detailed execution instructions.</p> <p>See Quick Start Guide for a complete tutorial.</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":"<p>For Users: - Input Data Format - Describes the PRISME dataset input structure - Configuration Parameters - Describes how to <code>setparams.m</code> for your own analysis - Running Workflows - Step-by-step execution guide</p> <p>For Developers: - Adding New Methods - Describes how to add a new method, how methods receive data from the code upstream, and how they must return the p-values</p> <ul> <li>Architecture Overview - Code organization and design principles</li> <li>C++ Integration - How to optimize your method with C++ </li> </ul>"},{"location":"#license","title":"License","text":"<p>MIT License - see GitHub repository for details.</p>"},{"location":"#support","title":"Support","text":"<ul> <li>GitHub Issues: Report bugs or request features</li> </ul>"},{"location":"developer/adding_methods/","title":"Adding New Statistical Methods","text":"<p>PRISME's architecture was designed to facilitate the addition of new statistical inference methods by creating a single MATLAB class file. This guide explains the API and provides examples.</p>"},{"location":"developer/adding_methods/#important-implement-one-sided-tests-only","title":"Important: Implement One-Sided Tests Only","text":"<p>Your method should implement one-sided tests. PRISME calls your method twice: once with the original statistics and once with negated statistics. This is because PRISME calculates power separately for positive and negative effects according to its algorithm. </p>"},{"location":"developer/adding_methods/#why","title":"Why","text":"<p>PRISME compares detected effects against ground truth by direction: - <code>tpr</code> - Power for correctly detected positive effects - <code>tpr_neg</code> - Power for correctly detected negative effects</p> <p>An effect is only counted as correctly detected if both: 1. The p-value is significant in the correct direction of the ground truth 2. The direction matches the ground truth</p> <p>Two-sided implementations will result in significance being marked repeatedly in tpr and tpr_neg. Please check the algorithm and power definition in the paper for more clarification. </p>"},{"location":"developer/adding_methods/#method-class-structure","title":"Method Class Structure","text":"<p>Place your method class in the <code>statistical_methods/</code> directory. The class must define specific properties and implement a <code>run_method</code> function.</p>"},{"location":"developer/adding_methods/#required-properties","title":"Required Properties","text":"<p><code>level</code> (string, required) - Determines what your method returns p-values for - Options:   - <code>'variable'</code> - One p-value per edge or voxel   - <code>'network'</code> - One p-value per network   - <code>'whole_brain'</code> - Single omnibus p-value</p> <p><code>permutation_based</code> (boolean, required) - <code>true</code> if your method uses permutation testing - <code>false</code> for parametric methods (getting p-values from a statistical distribution)</p>"},{"location":"developer/adding_methods/#optional-properties","title":"Optional Properties","text":"<p><code>submethod</code> (cell array, optional)</p> <ul> <li> <p>Specify multiple return approaches that share the same computation.</p> </li> <li> <p>Example: <code>{'FWER', 'FDR'}</code> for methods that support both corrections</p> </li> <li>When defined, <code>run_method</code> must return a struct with one field per submethod. For example, the method must return pvals.FWER and pvals.FDR. </li> <li>A submethod can extend beyond multiple comparisons. At any point, if you wish to reuse the calculations from a method into multiple outputs, please create new submethods. Submethods are simply a way to return more than one set of p-values from a single inference method</li> </ul> <p><code>permutations</code> (integer, optional) - Override the global permutation count for method-specific needs. More computationally extensive methods likely benefit from a number of permutation reductions - If not specified, uses <code>Params.n_perms</code></p> <p><code>method_params</code> (struct, optional) - A struct that stores method-specific parameters </p>"},{"location":"developer/adding_methods/#the-run_method-function","title":"The run_method Function","text":"<p>Your method receives data through key-value pairs passed to <code>run_method</code>:</p> <pre><code>methods\n    function pvals = run_method(obj, varargin)\n        % Convert key-value pairs to struct\n        params = struct(varargin{:});\n\n        % Extract inputs\n        STATS = params.statistical_parameters;\n        edge_stats = params.edge_stats;\n        network_stats = params.network_stats;\n        perm_edge = params.permuted_edge_data;\n        perm_network = params.permuted_network_data;\n\n        % Your method implementation here\n        pvals = your_computation(edge_stats, perm_edge, STATS);\n    end\nend\n</code></pre> <p>Key pattern: Convert <code>varargin</code> to a struct with <code>params = struct(varargin{:})</code>, then access fields directly.</p>"},{"location":"developer/adding_methods/#input-arguments","title":"Input Arguments","text":"<p>PRISME passes these arguments to <code>run_method</code>:</p> <p><code>statistical_parameters</code> (struct)</p> <ul> <li> <p><code>n_var</code> - Number of variables (edges or voxels)</p> </li> <li> <p><code>n_perms</code> - Number of permutations</p> </li> <li><code>variable_type</code> - Type of data ('edge' or 'node')</li> <li><code>mask</code> - Logical mask for flattening/unflattening data</li> <li><code>edge_groups</code> - Network assignments for each variable</li> <li><code>test_type</code> - Statistical test type ('t', 't2', or 'r')</li> <li><code>thresh</code> - T-statistic threshold (for cluster methods)</li> <li><code>alpha</code> - Significance threshold</li> <li><code>submethods</code> - Struct indicating which submethods to compute</li> <li>Helper functions: <code>unflatten_matrix</code>, flatten_matrix -  To avoid errors, please avoid using the mask for flattening</li> </ul> <p><code>edge_stats</code> (vector) - T-statistics for each variable from the current repetition - Size: <code>[n_var \u00d7 1]</code></p> <p><code>network_stats</code> (vector) - Average t-statistics for each network - Size: <code>[n_networks \u00d7 1]</code></p> <p><code>glm_parameters</code> (struct) - GLM fitting parameters (e.g., degrees of freedom)</p> <p><code>permuted_edge_data</code> (matrix, only if <code>permutation_based = true</code>) - T-statistics from permutations - Size: <code>[n_var \u00d7 n_perms]</code></p> <p><code>permuted_network_data</code> (matrix, only if <code>permutation_based = true</code>) - Network-averaged t-statistics from permutations - Size: <code>[n_networks \u00d7 n_perms]</code></p>"},{"location":"developer/adding_methods/#return-value","title":"Return Value","text":"<p>Single method (no submethods): - Return a vector of p-values - Size depends on <code>level</code>:   - <code>'variable'</code>: <code>[n_var \u00d7 1]</code>   - <code>'network'</code>: <code>[n_networks \u00d7 1]</code>   - <code>'whole_brain'</code>: <code>[1 \u00d7 1]</code></p> <p>Method with submethods: - Return a struct where each field is a submethod name - Each field contains the appropriate p-value vector</p> <pre><code>% Example with submethods\npvals.FWER = fwer_corrected_pvals;\npvals.FDR = fdr_corrected_pvals;\n</code></pre>"},{"location":"developer/adding_methods/#complete-examples","title":"Complete Examples","text":""},{"location":"developer/adding_methods/#example-1-simple-parametric-method","title":"Example 1: Simple Parametric Method","text":"<pre><code>classdef SimpleParametric\n    properties\n        level = 'variable';\n        permutation_based = false;\n    end\n\n    methods\n        function pvals = run_method(obj, varargin)\n            % Convert key-value pairs to struct\n            params = struct(varargin{:});\n\n            edge_stats = params.edge_stats;\n            dof = params.glm_parameters.dof;\n\n            % One-sided test: test if statistics are significantly positive\n            pvals = 1 - tcdf(edge_stats, dof);\n        end\n    end\nend\n</code></pre>"},{"location":"developer/adding_methods/#example-2-permutation-based-method","title":"Example 2: Permutation-Based Method","text":"<pre><code>classdef PermutationMethod\n    properties\n        level = 'variable';\n        permutation_based = true;\n    end\n\n    methods\n        function pvals = run_method(obj, varargin)\n            % Convert key-value pairs to struct\n            params = struct(varargin{:});\n\n            edge_stats = params.edge_stats;\n            perm_data = params.permuted_edge_data;\n\n            % Calculate p-values from permutation distribution (one-sided)\n            n_perms = size(perm_data, 2);\n            pvals = zeros(size(edge_stats));\n\n            for i = 1:length(edge_stats)\n                % Count permutations with values &gt;= observed statistic\n                n_extreme = sum(perm_data(i,:) &gt;= edge_stats(i));\n                pvals(i) = n_extreme / n_perms;\n            end\n        end\n    end\nend\n</code></pre>"},{"location":"developer/adding_methods/#example-3-method-with-submethods","title":"Example 3: Method with Submethods","text":"<pre><code>% Note: The Bonferroni and FDR functions below are examples only\nclassdef MultiCorrectionMethod\n    properties\n        level = 'variable';\n        permutation_based = false;\n        submethod = {'FWER', 'FDR'};\n    end\n\n    methods\n        function pvals = run_method(obj, varargin)\n            % Convert key-value pairs to struct\n            params = struct(varargin{:});\n\n            edge_stats = params.edge_stats;\n            dof = params.glm_parameters.dof;\n            STATS = params.statistical_parameters;\n\n            % Compute uncorrected p-values (one-sided)\n            uncorrected = 1 - tcdf(edge_stats, dof);\n\n            % Initialize output struct\n            pvals = struct();\n\n            % Apply FWER correction if requested\n            if STATS.submethods.FWER\n                pvals.FWER = bonferroni_correction(uncorrected);\n            end\n\n            % Apply FDR correction if requested\n            if STATS.submethods.FDR\n                pvals.FDR = fdr_correction(uncorrected);\n            end\n        end\n    end\nend\n</code></pre>"},{"location":"developer/adding_methods/#testing-your-method","title":"Testing Your Method","text":"<p>Please check <code>power_calculator_test_script.m</code>. It uses several datasets with known effects to test inference methods. It should work as a sanity test.</p> <p>Also, please use the developer parameters for a test run to check if the method was correctly implemented.</p>"},{"location":"developer/architecture/","title":"Architecture Overview","text":"<p>Repetition Calculation </p> <p>PRISME's architecture organizes computation across four hierarchical levels, each with a dedicated script. </p>"},{"location":"developer/architecture/#four-levels-of-organization","title":"Four Levels of Organization","text":""},{"location":"developer/architecture/#1-study-level-organization","title":"1. Study-Level Organization","text":"<p>The outermost level loops over all studies defined in the <code>outcome</code> structure. For each study, PRISME automatically infers the test type by analyzing the data structure:</p> <ul> <li>One-sample t-test: When contrasts between conditions are available</li> <li>Two-sample t-test: When categorical data exists for exactly two groups</li> <li>Correlation analysis: When continuous measures are present</li> </ul> <p>This specification spares manual definition and ensures each analysis is compatible with the data supplied. See Input Data Format for details on the inference logic.</p>"},{"location":"developer/architecture/#2-subject-level-sampling","title":"2. Subject-Level Sampling","text":"<p>Within each study, this level loops over the sample sizes specified in <code>Params.list_of_nsubset</code>. Since PRISME generates one output file per study and sample size, this level handles file-based checkpointing for resumption after interruptions. If the file for this study and subject-level has all repetitions completed, it skips to the next loop.</p> <p>Overall, for each sample size:</p> <ul> <li>Manages subject identifiers for subsampling</li> <li>Constructs appropriate design matrices for each repetition </li> <li>Tracks completion status by checking existing output files</li> <li>Resumes from checkpoints when calculations are interrupted</li> </ul>"},{"location":"developer/architecture/#3-batch-level-management","title":"3. Batch-Level Management","text":"<p>This level organizes repetitions into configurable batches (set by <code>Params.batch_size</code>). Batching helps with memory management and checkpointing. Trade-off: Larger batches require more RAM but reduce disk I/O overhead. Smaller batches use less RAM but save to disk more frequently.</p> <p>The batch manager: - Group repetitions into processing units - Balances memory efficiency - Implements the checkpoint system - When a batch is completed, the repetitions are saved to the file - Saves results incrementally after each batch completes</p>"},{"location":"developer/architecture/#4-parallel-execution-level","title":"4. Parallel Execution Level","text":"<p>The innermost level distributes computational workload across available CPU cores. PRISME parallelizes at the repetition level because:</p> <ul> <li>GLM fitting and statistical method inference are the most computationally intensive parts of the code</li> <li>Each repetition is independent (no communication overhead)</li> <li>With 500 recommended repetitions, parallelization enables near-linear scaling</li> </ul> <p>Each worker processes a complete repetition independently, including: - GLM fitting for original and permuted data - Applying all statistical inference methods - Computing p-values</p> <p>Set <code>Params.parallel = true</code> and <code>Params.n_workers</code> to the number of available cores to enable parallel execution.</p>"},{"location":"developer/architecture/#computational-flow","title":"Computational Flow","text":"<pre><code>Study Loop (Study 1, Study 2, ...)\n  \u2514\u2500 Sample Size Loop (n=40, n=80, ...)\n      \u2514\u2500 Batch Loop (Batch 1, Batch 2, ...)\n          \u2514\u2500 Parallel Execution (Rep 1, Rep 2, ... Rep batch_size)\n              \u251c\u2500 Subsample subjects\n              \u251c\u2500 Fit GLM + permutations\n              \u251c\u2500 Apply statistical methods\n              \u2514\u2500 Return p-values\n          \u2514\u2500 Save batch results (checkpoint)\n</code></pre> <p>Ground Truth Calculation</p>"},{"location":"developer/architecture/#unified-pipeline","title":"Unified Pipeline","text":"<p>Although the algorithm describes two computational paths (repetitions and ground truth), the architecture implements both within a unified framework. The ground truth calculation is a special case of the repetition workflow where: - Only one repetition is performed - The entire dataset (N subjects) is used - A dummy statistical inference method maintains code consistency - Only the GLM fit results are extracted</p> <p>This unification simplifies maintenance. One code changes automatically affect both workflows.</p>"},{"location":"developer/cpp_integration/","title":"C++ Integration","text":"<p>PRISME supports C++ implementations of statistical methods for performance-critical computations through MATLAB mex. </p> <p>Current C++ implementations include TFCE, Cluster Size, and cNBS methods.</p>"},{"location":"developer/cpp_integration/#file-organization","title":"File Organization","text":"<pre><code>statistical_methods/\n\u251c\u2500\u2500 mex_scripts/              # C++ source files (.cpp)\n\u2502   \u251c\u2500\u2500 apply_tfce_cpp.cpp\n\u2502   \u251c\u2500\u2500 size_pval_cpp.cpp\n\u2502   \u251c\u2500\u2500 constrained_pval_cpp.cpp\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 mex_binaries/             # Compiled MEX files (generated)\n    \u251c\u2500\u2500 apply_tfce_cpp.mexa64\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"developer/cpp_integration/#compilation","title":"Compilation","text":"<p>Compile all C++ methods by running:</p> <pre><code>compile_mex()\n</code></pre> <p>This script: 1. Cleans existing MEX binaries 2. Compiles all C++ files from <code>mex_scripts/</code> 3. Stores compiled binaries in <code>mex_binaries/</code> 4. Adds the binary directory to MATLAB path</p> <p>Compilation is platform-specific - the script will generate the appropriate binary format for your system (.mexa64 for Linux, .mexmaci64 for macOS, .mexw64 for Windows).</p>"},{"location":"developer/cpp_integration/#naming-convention","title":"Naming Convention","text":"<p>C++ implementations use the <code>_cpp</code> suffix: - MATLAB version: <code>Fast_TFCE.m</code> - C++ version: <code>Fast_TFCE_cpp.m</code> (wrapper) + <code>apply_tfce_cpp.cpp</code> (implementation)</p> <p>The MATLAB wrapper class calls the compiled MEX function.</p>"},{"location":"developer/cpp_integration/#adding-a-c-method","title":"Adding a C++ Method","text":""},{"location":"developer/cpp_integration/#step-1-write-the-c-function","title":"Step 1: Write the C++ Function","text":"<p>Create your C++ file in <code>statistical_methods/mex_scripts/</code>:</p> <pre><code>// my_method_cpp.cpp\n#include \"mex.h\"\n\nvoid mexFunction(int nlhs, mxArray *plhs[], int nrhs, const mxArray *prhs[]) {\n    // Get input data\n    double *data = mxGetPr(prhs[0]);\n    mwSize n = mxGetM(prhs[0]);\n\n    // Allocate output\n    plhs[0] = mxCreateDoubleMatrix(n, 1, mxREAL);\n    double *output = mxGetPr(plhs[0]);\n\n    // Your computation here\n    for (mwSize i = 0; i &lt; n; i++) {\n        output[i] = data[i] * 2.0;  // Example\n    }\n}\n</code></pre>"},{"location":"developer/cpp_integration/#step-2-register-in-compile_mex","title":"Step 2: Register in compile_mex","text":"<p>Add your file to the <code>source_files</code> list in <code>compile_mex.m</code>:</p> <pre><code>source_files = {\n    'statistical_methods/mex_scripts/apply_tfce_cpp.cpp', ...\n    'statistical_methods/mex_scripts/my_method_cpp.cpp', ...  % Add here\n    % ... other files\n};\n</code></pre>"},{"location":"developer/cpp_integration/#step-3-create-matlab-wrapper","title":"Step 3: Create MATLAB Wrapper","text":"<p>Create a MATLAB class that calls your C++ function:</p> <pre><code>classdef My_Method_cpp\n    properties\n        level = 'variable';\n        permutation_based = true;\n    end\n\n    methods\n        function pvals = run_method(obj, varargin)\n            params = struct(varargin{:});\n            edge_stats = params.edge_stats;\n            perm_data = params.permuted_edge_data;\n\n            % Call compiled C++ function\n            pvals = my_method_cpp(edge_stats, perm_data);\n        end\n    end\nend\n</code></pre>"},{"location":"developer/cpp_integration/#step-4-compile-and-test","title":"Step 4: Compile and Test","text":"<pre><code>% Compile\ncompile_mex();\n\n% Test with developer mode\nParams = setparams();\nParams.all_cluster_stat_types = {'My_Method_cpp'};\nParams.testing = true;\nrepetition_calculator();\n</code></pre>"},{"location":"developer/cpp_integration/#memory-compatibility","title":"Memory Compatibility","text":"<p>Critical: Ensure all MATLAB variables are cast to <code>double</code> before passing to C++ functions:</p> <pre><code>% Correct\npvals = my_cpp_function(double(edge_stats));\n\n% Incorrect - may cause memory errors\npvals = my_cpp_function(edge_stats);  % If edge_stats is single precision\n</code></pre> <p>C++ MEX functions expect double precision by default. Type mismatches can cause crashes or incorrect results.</p>"},{"location":"developer/cpp_integration/#validation","title":"Validation","text":"<p>When replacing a MATLAB method with C++:</p> <ol> <li>Keep both versions initially</li> <li>Run both on test data</li> <li>Verify identical outputs</li> <li>Benchmark performance improvement</li> </ol> <p>PRISME's permutation recycling ensures both versions receive identical input, making validation straightforward.</p>"},{"location":"developer/cpp_integration/#computational-time-performance-benchmarking","title":"Computational Time Performance Benchmarking","text":"<p>Statistical methods are timed during PRISME calculation execution. Use this feature to benchmark the C++ implementation and see if it is the best for your statistical inference method.</p>"},{"location":"user_guide/input_format/","title":"Input Data Format","text":"<p>PRISME accepts neuroimaging data as MATLAB <code>.mat</code> files with a specific structure. This section describes the required format.</p>"},{"location":"user_guide/input_format/#overview","title":"Overview","text":"<p>Your dataset file must contain three components:</p> <ul> <li><code>brain_data</code> - The neuroimaging data (FC matrices or voxel activations)</li> <li><code>study_info</code> - Metadata about the dataset</li> <li><code>outcome</code> - Study definitions and test specifications</li> </ul>"},{"location":"user_guide/input_format/#brain_data","title":"brain_data","text":"<p>The <code>brain_data</code> component is a MATLAB struct where each field represents a condition or task (e.g., REST, EMOTION, SOCIAL).</p> <p>Each condition field contains:</p> <ul> <li>data: Flattened neuroimaging data where each column represents one subject</li> <li>For FC data: Each row is an edge measuring the correlation between two ROI time series</li> <li>For voxel data: Each row is a voxel measuring activation (referred to as nodes in graph representation)</li> <li>sub_ids: Subject IDs corresponding to each column in the data matrix</li> <li>mask: (Optional - can be stored in study_info if consistent across tasks) A logical structure that maps flattened variables back to their original spatial positions (ROI pairs for connectivity matrices, brain coordinates for voxels)</li> </ul>"},{"location":"user_guide/input_format/#study_info-structure","title":"study_info Structure","text":"<p>The <code>study_info</code> component contains metadata describing your dataset.</p> <p>Required fields:</p> <ul> <li><code>dataset</code> - Dataset identifier (e.g., 'HCP', 'ABCD')</li> <li><code>map</code> - Data type (e.g., 'functional_connectivity', 'activation')</li> <li><code>mask</code> - A logical structure that maps flattened variables to their original spatial positions</li> </ul>"},{"location":"user_guide/input_format/#outcome-structure","title":"outcome Structure","text":"<p>The <code>outcome</code> component defines the studies PRISME will analyze. Each study is stored as a struct, and the number of elements in <code>outcome</code> equals the number of studies.</p> <p>Required fields for all test types:</p> <ul> <li><code>sub_ids</code> - Subject identifiers included in this study (can also be stored in brain_data)</li> <li><code>reference_condition</code> - Baseline condition (e.g., 'REST')</li> <li><code>category</code> - Study category label</li> </ul> <p>Additional fields by test type:</p> <p>For correlation analyses: - <code>score</code> - Continuous measures (e.g., age, behavioral scores) - <code>score_label</code> - Description of the measure</p> <p>For condition contrasts: - <code>contrast</code> - For studies analyzing the difference between two conditions, this specifies both conditions to contrast</p>"},{"location":"user_guide/input_format/#test-type-inference","title":"Test Type Inference","text":"<p>PRISME automatically infers the test type (one-sample, two-sample, or correlation) from the <code>outcome</code> structure. The function <code>infer_test_from_data</code> uses the following logic:</p> <ol> <li>One-sample t-test: If <code>score</code> contains only one unique value, or if <code>contrast</code> specifies a single condition</li> <li>Correlation test: If <code>score</code> is numeric with more than 2 unique values</li> <li>Two-sample or paired t-test: If <code>score</code> has exactly 2 unique values, or if <code>contrast</code> specifies 2 conditions:</li> <li>Calculates subject overlap between the two groups</li> <li>If overlap \u2265 unique subjects \u2192 One-sample t-test (paired design)</li> <li>If overlap &lt; unique subjects \u2192 Two-sample t-test (independent groups)</li> </ol>"},{"location":"user_guide/input_format/#converting-your-data","title":"Converting Your Data","text":"<p>If your data is not in PRISME format, you'll need to write a conversion script that matches the description above.  Please follow the data description.  We also provide dummy datasets that are used for testing in the repository. Please check <code>test</code> named datasets under  <code>/data/</code> as a reference to the input data format.</p>"},{"location":"user_guide/input_format/#example-datasets","title":"Example Datasets","text":"<p>Preprocessed HCP and ABCD data in PRISME format can be obtained from the authors upon verification of approved data access from the respective repositories.</p>"},{"location":"user_guide/parameters/","title":"Configuration Parameters","text":"<p>This page describes the parameters in <code>setparams.m</code>. This file is located in the project root directory and serves as the configuration file for PRISME. Please modify it to run your analysis. We recommend reviewing the file before going through this guide.</p>"},{"location":"user_guide/parameters/#quick-reference","title":"Quick Reference","text":"<ul> <li><code>data_dir</code> - Path to your dataset used for the analysis</li> <li><code>list_of_nsubset</code> - List of sample sizes to perform the power calculation</li> <li><code>n_repetitions</code> - Number of subsampling repetitions to be used</li> <li><code>all_cluster_stat_types</code> - List of statistical inference methods used in the analysis </li> <li><code>n_perms</code> - Number of permutations used for the non-parametric inference methods</li> </ul>"},{"location":"user_guide/parameters/#data-and-output-paths","title":"Data and Output Paths","text":"<p>All attributes here are fields in the Params struct defined in the setparams.m file.</p> <p><code>data_dir</code> (string, required)</p> <p>Path to the input dataset <code>.mat</code> file used for the power calculation. See Input Data Format for more instructions.</p> <pre><code>Params.data_dir = './data/my_dataset.mat';\n</code></pre> <p><code>output</code> (string, optional)</p> <p>Name for the output directory. If not specified, defaults to the dataset filename. PRISME saves the results from the subsampling repetitions in a directory folder called <code>repetitions</code>, the ground truth calculation in <code>ground_truth</code>, and the power calculation in <code>power_calculation</code>. All three folders are contained in a directory named after Params.output within <code>power_calculator_results</code>.</p> <pre><code>Params.output = 'my_power_analysis';\n</code></pre> <p><code>save_directory</code> (string, optional)</p> <p>The directory where all results are saved. Default: <code>'./power_calculator_results/'</code></p> <pre><code>Params.save_directory = './my_results/';\n</code></pre> <p><code>subsample_file_type</code> (string, optional)</p> <p>Output file format: <code>'full_file'</code> or <code>'compact_file'</code>. Full files save all relevant p-values and all estimated t-statistics. Therefore, they consume significantly more storage and are slower to checkpoint. Compact files only save the average t-statistic and the number of times each variable was found significant. Default: <code>'compact_file'</code></p> <pre><code>Params.subsample_file_type = 'compact_file';\n</code></pre> <p><code>atlas_file</code> (string or NaN, optional)</p> <p>Path to a custom brain atlas file. Default: NaN. If no atlas is provided, PRISME cannot assign variables to networks, and network-level inference methods will not be performed.</p> <pre><code>Params.atlas_file = './atlases/schaefer_268.mat';\n% or\nParams.atlas_file = NaN;  % No atlas\n</code></pre> <p><code>recalculate</code> (boolean, optional)</p> <p>If <code>true</code>, recalculates existing results. If <code>false</code>, resumes from existing checkpoints. Default: <code>false</code></p> <pre><code>Params.recalculate = true;  % Force recalculation\n</code></pre> <p><code>list_of_nsubset</code> (cell array, required)</p> <p>Sample sizes to test in your power analysis.</p> <pre><code>Params.list_of_nsubset = {20, 40, 80, 120, 200};\n</code></pre> <p>Note: For two-sample t-tests, this is the size per group (total N = 2n).</p> <p><code>n_repetitions</code> (integer, required)</p> <p>Number of subsampling repetitions.</p> <pre><code>Params.n_repetitions = 100;\n</code></pre> <p><code>batch_size</code> (integer, optional)</p> <p>Number of repetitions per checkpoint batch. Results are only saved to disk once a batch is completed. Therefore, this parameter balances how much data will be stored in RAM before saving it to disk and checkpointing. The larger it is, the faster the overall calculation, but the more RAM memory will be necessary.</p> <pre><code>Params.batch_size = 50;  % Process 50 repetitions before saving\n</code></pre> <p><code>tests_to_skip</code> (function handle, optional)</p> <p>Function handle that defines which studies to skip based on their index. Default skips nothing. This will be replaced in a future update.</p> <pre><code>% Skip studies 5-10\nranges = {[5, 10]};\nParams.tests_to_skip = @(x) any(cellfun(@(r) (x &gt;= r(1)) &amp;&amp; (x &lt;= r(2)), ranges));\n</code></pre>"},{"location":"user_guide/parameters/#statistical-settings","title":"Statistical Settings","text":"<p><code>all_cluster_stat_types</code> (cell array, required)</p> <p>Statistical inference methods to evaluate. Some of the available methods:</p> <ul> <li><code>'Parametric'</code> - Parametric inference using t-distribution</li> <li><code>'Size_cpp'</code> - Cluster-size inference with C++ implementation</li> <li><code>'Fast_TFCE_cpp'</code> - TFCE with incremental cluster and C++ </li> <li><code>'Constrained_cpp'</code> - cNBS with C++ implementation</li> <li><code>'Omnibus_cNBS'</code> - Multivariate whole-brain test</li> </ul> <p>Non-C++ versions are named identically without the <code>_cpp</code> suffix.</p> <pre><code>Params.all_cluster_stat_types = {'Parametric', 'Fast_TFCE_cpp', 'Constrained_cpp'};\n</code></pre> <p><code>all_submethods</code> (cell array, optional)</p> <p>Multiple comparison correction methods. Current options: <code>'FWER'</code>, <code>'FDR'</code></p> <pre><code>Params.all_submethods = {'FWER', 'FDR'};\n</code></pre> <p><code>n_perms</code> (integer, required for non-parametric methods)</p> <p>Number of permutations for non-parametric inference.</p> <pre><code>Params.n_perms = 1000;\n</code></pre> <p><code>force_permute</code> (boolean, optional)</p> <p>If <code>true</code>, forces permutation generation even if parametric methods that don't require permutations are chosen. Default: <code>false</code></p> <pre><code>Params.force_permute = true;\n</code></pre> <p><code>pthresh_second_level</code> (float, optional)</p> <p>Significance threshold (alpha level). This significance threshold is applied to multiple-comparison corrected p-values when applicable.</p> <pre><code>Params.pthresh_second_level = 0.05;  % 5% significance level\n</code></pre> <p><code>tthresh_first_level</code> (float, optional)</p> <p>T-statistic threshold for initial cluster formation. Only used by the Cluster Size method. Default: 3.1. This parameter will be moved into method-specific implementations in a future update.</p> <pre><code>Params.tthresh_first_level = 3.1;  % Approximately p=0.001-0.005\n</code></pre> <p><code>tpr_dthresh</code> (float, optional)</p> <p>Threshold for defining true effects from ground truth. If the magnitude is above this value, the ground truth effect is considered a true effect. Default: 0</p> <pre><code>Params.tpr_dthresh = 0;\n</code></pre> <p><code>save_significance_thresh</code> (float, optional)</p> <p>Only p-values below this threshold are saved to disk (memory optimisation). Default: 0.15. This only applies to the full_file structure. Compact files only save the number of times a variable was found significant.</p> <pre><code>Params.save_significance_thresh = 0.15;\n</code></pre> <p><code>cluster_size_type</code> (string, optional)</p> <p>For Cluster Size method: <code>'Extent'</code> (cluster size) or <code>'Intensity'</code> (cluster mass). Default: <code>'Extent'</code>. This parameter will be moved into method-specific implementations in a future update.</p> <pre><code>Params.cluster_size_type = 'Extent';\n</code></pre>"},{"location":"user_guide/parameters/#parallel-processing","title":"Parallel Processing","text":"<p><code>parallel</code> (boolean, optional)</p> <p>Enable parallel processing across repetitions. Default: <code>true</code></p> <pre><code>Params.parallel = true;\n</code></pre> <p><code>n_workers</code> (integer, optional)</p> <p>Number of parallel workers. Set to the number of available CPU cores. Default: <code>10</code></p> <pre><code>Params.n_workers = 16;  % Use 16 cores\n</code></pre>"},{"location":"user_guide/parameters/#advanced-parameters","title":"Advanced Parameters","text":"<p><code>gt_origin</code> (string, deprecated)</p> <p>Ground truth calculation origin. Deprecated.</p> <pre><code>Params.gt_origin = 'power_calculator';\n</code></pre> <p><code>nbs_dir</code> (string, internal)</p> <p>Path to NBS directory for internal dependencies.</p> <pre><code>Params.nbs_dir = './NBS1.2';\n</code></pre> <p><code>other_scripts_dir</code> (string, internal)</p> <p>Deprecated - path to old cNBS scripts.</p> <pre><code>Params.other_scripts_dir = './NBS_benchmarking/support_scripts/';\n</code></pre>"},{"location":"user_guide/parameters/#developer-options","title":"Developer Options","text":"<p>These parameters enable faster execution for testing and development. Do not use for actual power calculations.</p> <p><code>testing</code> (boolean, optional)</p> <p>Enables testing mode with reduced parameters. Default: <code>false</code></p> <pre><code>Params.testing = true;\n</code></pre> <p><code>test_n_perms</code> (integer, optional)</p> <p>Reduced permutation count for testing. Default: <code>10</code></p> <pre><code>Params.test_n_perms = 10;\n</code></pre> <p><code>test_n_repetitions</code> (integer, optional)</p> <p>Reduced repetition count for testing. Default: <code>5</code></p> <pre><code>Params.test_n_repetitions = 5;\n</code></pre> <p><code>test_n_workers</code> (integer, optional)</p> <p>Worker count for testing. Default: <code>1</code></p> <pre><code>Params.test_n_workers = 1;\n</code></pre> <p><code>test_disable_save</code> (boolean, optional)</p> <p>Disables saving results during testing. Default: <code>false</code></p> <pre><code>Params.test_disable_save = true;\n</code></pre>"},{"location":"user_guide/workflows/","title":"Running Workflows","text":"<p>PRISME uses a three-step workflow to calculate statistical power. This page describes how to run each step and interpret the outputs.</p>"},{"location":"user_guide/workflows/#quick-start","title":"Quick Start","text":"<p>After making the necessary changes to the <code>setparams.m</code> script (see Configuration Parameters), run these three commands:</p> <pre><code>% Step 1: Generate subsampled repetitions (this takes the longest and uses chec)\nrepetition_calculator;\n\n% Step 2: Calculate ground truth from full dataset (normally fast)\ncalculate_gt;\n\n% Step 3: Calculate power by comparing repetitions to ground truth (normally fast)\ncalculate_power;\n</code></pre>"},{"location":"user_guide/workflows/#workflow-details","title":"Workflow Details","text":""},{"location":"user_guide/workflows/#step-1-subsampling-repetitions-repetition_calculatorm","title":"Step 1: Subsampling Repetitions (<code>repetition_calculator.m</code>)","text":"<p>This script performs the repeated subsampling analysis. For each combination of study, sample size, and inference method, it:</p> <ol> <li>Randomly samples n subjects from the full dataset</li> <li>Fits a GLM to generate t-statistics for each brain variable</li> <li>Applies the same GLM to permuted versions of the data</li> <li>Passes t-statistics to all specified inference methods</li> <li>Each method produces p-values indicating statistical significance</li> </ol> <p>This process repeats R times (specified by <code>Params.n_repetitions</code>).</p> <p>Output location: <code>./power_calculator_results/[output_name]/repetitions/</code></p> <p>Filename convention: <code>output_name-outcome-test_type-subject_number</code></p> <p>Checkpoint system: Results are saved after each batch of repetitions (set by <code>Params.batch_size</code>). If interrupted, the script automatically resumes from the last checkpoint.</p>"},{"location":"user_guide/workflows/#output-structure","title":"Output Structure","text":"<p>Each output file is a MATLAB struct containing:</p> <ul> <li><code>edge_level_stats</code> - Sum of t-statistics for each variable (edge or voxel) across all repetitions</li> <li><code>network_level_stats</code> - Sum of t-statistics for each network across all repetitions</li> <li><code>edge_mean_squared_error</code> - Mean squared error for edge-level statistics (used to calculate variance)</li> <li><code>network_mean_squared_error</code> - Mean squared error for network-level statistics (used to calculate variance)</li> <li><code>meta_data</code> - Calculation parameters and metadata</li> <li><code>[inference_method_1]</code> - Results from first inference method</li> <li><code>total_time</code> - Cumulative computation time for this method across all repetitions</li> <li><code>positives</code> - Count of how many times each variable was found significant (positive effects)</li> <li><code>negatives</code> - Count of how many times each variable was found significant (negative effects)</li> <li><code>total_calculations</code> - Number of repetitions processed</li> <li><code>[inference_method_2]</code> - Results from the second inference method</li> <li>... (one field per method)</li> </ul> <p>Note: To calculate average t-statistics and variance, calculate_power uses this accumated sums </p>"},{"location":"user_guide/workflows/#step-2-ground-truth-calculation-calculate_gtm","title":"Step 2: Ground Truth Calculation (<code>calculate_gt.m</code>)","text":"<p>This script estimates ground truth effects using all N subjects in the dataset. It:</p> <ol> <li>Fits the GLM to the complete dataset</li> <li>Computes t-statistics for all variables</li> <li>Derives network-level statistics by averaging variable-level t-statistics</li> <li>Saves results for comparison with subsampled repetitions</li> </ol> <p>Output location: <code>./power_calculator_results/[output_name]/ground_truth/</code></p> <p>Filename convention: <code>output_name-outcome-Ground_Truth-subject_number</code></p>"},{"location":"user_guide/workflows/#output-structure_1","title":"Output Structure","text":"<ul> <li><code>edge_level_stats</code> - T-statistics for each variable</li> <li><code>network_level_stats</code> - T-statistics for each network</li> <li><code>meta_data</code> - Calculation parameters</li> <li><code>Ground_Truth</code> - Placeholder method field (returns p-value of 1 for consistency)</li> </ul>"},{"location":"user_guide/workflows/#step-3-power-calculation-calculate_power_per_methodm","title":"Step 3: Power Calculation (<code>calculate_power_per_method.m</code>)","text":"<p>This script calculates statistical power by comparing subsampled repetitions against ground truth. It:</p> <ol> <li>Constructs ground truth significance vectors based on t-statistic signs</li> <li>Positive effects: where <code>edge_level_stats</code> &gt; <code>tpr_dthresh</code> threshold (0 by default)</li> <li>Negative effects: where <code>edge_level_stats</code> &lt; <code>-tpr_dthresh</code> threshold (0 by default)</li> <li>For whole-brain inference: registers a true positive if any network has a non-zero effect</li> <li>For each method: loads the <code>positives</code> and <code>negatives</code> counts from repetition files (which track how many times each variable was found significant across all repetitions)</li> <li>Calculates power by dividing these counts by the total number of repetitions (<code>total_calculations</code>)</li> </ol> <p>Output location: <code>./power_calculator_results/power_calculation/[output_name]/</code></p> <p>Filename convention: <code>pr-output_name-outcome-test_type-subject_number</code></p>"},{"location":"user_guide/workflows/#output-structure_2","title":"Output Structure","text":"<ul> <li><code>meta_data</code> - Calculation parameters</li> <li><code>edge_level_stats_mean</code> - Mean t-statistics for each variable across repetitions</li> <li><code>network_level_stats_mean</code> - Mean t-statistics for each network across repetitions</li> <li><code>edge_level_stats_std</code> - Standard deviation of t-statistics for each variable</li> <li><code>network_level_stats_std</code> - Standard deviation of t-statistics for each network</li> <li><code>[inference_method_1]</code> - Power results for first method (e.g., <code>Exact_FC_TFCE_cpp</code>)</li> <li><code>tpr</code> - True positive rate (power): proportion of correctly detected positive effects</li> <li><code>tpr_neg</code> - True positive rate for negative effects</li> <li><code>meta_data</code> - Method-specific metadata</li> <li><code>[inference_method_2]</code> - Power results for the second method</li> <li>... (one field per method)</li> </ul> <p>Note: The <code>tpr</code> (true positive rate) fields directly represent statistical power for each variable or network, calculated as the proportion of repetitions where the effect was correctly detected.</p>"},{"location":"user_guide/workflows/#resuming-interrupted-calculations","title":"Resuming Interrupted Calculations","text":"<p>If <code>repetition_calculator</code> is interrupted:</p> <ol> <li>The script automatically detects already existing files and missing repetitions from each file</li> <li>Run <code>repetition_calculator</code> again (or \u2018calculate_gt\u2019)</li> <li>Calculation resumes from the last completed batch</li> </ol> <p>To force a complete recalculation, set <code>Params.recalculate = true</code>.</p>"}]}